{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_BTU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJxEBj2Ve0dr"
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1zfGImXfSeL"
      },
      "source": [
        "class BTU(torch.nn.Module):\n",
        "  def __init__(self, temp=0.001):\n",
        "      super(BTU, self).__init__()\n",
        "      self.temp = temp\n",
        "\n",
        "  def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "      return 1 / (1 + torch.exp(-input/self.temp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLEXsW-DfUCK"
      },
      "source": [
        "class Linear(torch.nn.Module):\n",
        "  def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None:\n",
        "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "    super(Linear, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.weight = nn.Parameter(torch.empty((in_features, out_features), **factory_kwargs))\n",
        "    if bias:\n",
        "        self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs))\n",
        "    else:\n",
        "        self.register_parameter('bias', None)\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self) -> None:\n",
        "    self.weight = nn.Parameter(torch.rand([self.in_features, self.out_features]))\n",
        "    if self.bias is not None:\n",
        "      self.bias = nn.Parameter(torch.rand([self.out_features]))\n",
        "\n",
        "  def set_weights(self, w, b) -> None:\n",
        "    tensor_w = nn.Parameter(torch.tensor(w))\n",
        "    tensor_b = nn.Parameter(torch.tensor(b))\n",
        "    if torch.Size(self.weight.shape) != torch.Size(tensor_w.shape):\n",
        "      print('Invalid weight size')\n",
        "    elif torch.Size(self.bias.shape) != torch.Size(tensor_b.shape):\n",
        "      print('Invalid bias size')\n",
        "    else:\n",
        "      self.weight = tensor_w\n",
        "      self.bias = tensor_b\n",
        "\n",
        "  def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.matmul(input, self.weight) + self.bias\n",
        "\n",
        "  def extra_repr(self) -> str:\n",
        "    return 'in_features={}, out_features={}, bias={}'.format(\n",
        "        self.in_features, self.out_features, self.bias is not None\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8gWLqy4faXn"
      },
      "source": [
        "dim = 2\n",
        "out_dim = 1\n",
        "temp = 0.001\n",
        "\n",
        "class Network(torch.nn.Module):\n",
        "  def __init__(self, k, bypass=True):\n",
        "    super().__init__()\n",
        "    self.bypass = bypass\n",
        "    self.hidden = Linear(dim, k)\n",
        "    if self.bypass:\n",
        "      self.output = Linear(k + dim, out_dim)\n",
        "    else:\n",
        "      self.output = Linear(k, out_dim)\n",
        "    self.BTU = BTU(temp)\n",
        "\n",
        "  def set_weights(self, w, b, layer):\n",
        "    if layer == 'hidden':\n",
        "      self.hidden.set_weights(w, b)\n",
        "    elif layer == 'output':\n",
        "      self.output.set_weights(w, b)\n",
        "  \n",
        "  def forward(self, input):\n",
        "    z1 = self.hidden(input)\n",
        "    y1 = self.BTU(z1)\n",
        "    if self.bypass:\n",
        "      y1_concat = torch.cat((input, y1), 1)\n",
        "      z2 = self.output(y1_concat)\n",
        "    else:\n",
        "      z2 = self.output(y1)\n",
        "    return self.BTU(z2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShBK6W8yse6V"
      },
      "source": [
        "def loss(x, t, print_deltas=False):\n",
        "  squared_deltas = torch.square(model(x) - t)\n",
        "  if print_deltas:\n",
        "    print(squared_deltas)\n",
        "  return torch.sum(squared_deltas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC5MocoRqFrC"
      },
      "source": [
        "xor_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "t = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "truth_table = torch.cat((xor_train, t), 1)\n",
        "\n",
        "def print_network_details(model):\n",
        "  print('Weights and bias:')\n",
        "  for param in model.parameters():\n",
        "    print(param)\n",
        "  print('Loss:')\n",
        "  print(loss(xor_train, t))\n",
        "  print('Truth table:')\n",
        "  print(truth_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucT-Fnc7ujY8"
      },
      "source": [
        "**K = 1** (with bypass)\n",
        "\n",
        "Hidden layer: \n",
        "1 unit, w = [1, 1], b = -1.5\n",
        "\n",
        "Output layer:\n",
        "1 unit, w = [1, 1, -2], b = -0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw6O2d3WsV4Y",
        "outputId": "45667d54-0504-4ec8-8c5a-460155df184f"
      },
      "source": [
        "model = Network(1, bypass=True)\n",
        "model.set_weights([[1.], [1.]], [-1.5], 'hidden')\n",
        "model.set_weights([[1.], [1.], [-2.]], [-.5], 'output')\n",
        "print_network_details(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights and bias:\n",
            "Parameter containing:\n",
            "tensor([[1.],\n",
            "        [1.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-1.5000], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 1.],\n",
            "        [ 1.],\n",
            "        [-2.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.5000], requires_grad=True)\n",
            "Loss:\n",
            "tensor(0., grad_fn=<SumBackward0>)\n",
            "Truth table:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_jLC5lXumz-"
      },
      "source": [
        "**K = 2** (without bypass)\n",
        "\n",
        "Hidden layer: \n",
        "2 units, w = [[1, -1], [-1, 1]], b = [-0.5, -0.5]\n",
        "\n",
        "Output layer:\n",
        "1 unit, w = [1.5, 1.5], b = -0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KQFjAOjcKRc",
        "outputId": "7726d2ab-0649-4284-c2ff-59e999072018"
      },
      "source": [
        "model = Network(2, bypass=False)\n",
        "model.set_weights([[1., -1.], [-1., 1.]], [-.5, -.5], 'hidden')\n",
        "model.set_weights([[1.5], [1.5]], [-.5], 'output')\n",
        "print_network_details(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights and bias:\n",
            "Parameter containing:\n",
            "tensor([[ 1., -1.],\n",
            "        [-1.,  1.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.5000, -0.5000], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[1.5000],\n",
            "        [1.5000]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.5000], requires_grad=True)\n",
            "Loss:\n",
            "tensor(0., grad_fn=<SumBackward0>)\n",
            "Truth table:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIUY2RzPupv8"
      },
      "source": [
        "**K = 4** (without bypass)\n",
        "\n",
        "Hidden layer: \n",
        "4 units, w = [[-1, -1, 1, 1], [-1, 1, -1, 1]], b = [-0.5, -0.5, -0.5, -1.5]\n",
        "\n",
        "Output layer:\n",
        "1 unit, w = [-1, 1, 1, -1], b = -0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDKxUB70sZIX",
        "outputId": "29f6d3fd-2c4c-4fa9-9937-1b8f48fcca4f"
      },
      "source": [
        "model = Network(4, bypass=False)\n",
        "model.set_weights([[-1., 1., -1., 1.]], [.5, -.5, -.5, -1.5], 'hidden')\n",
        "model.set_weights([[-1.], [1.], [1.], [-1.]], [-.5], 'output')\n",
        "print_network_details(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid weight size\n",
            "Weights and bias:\n",
            "Parameter containing:\n",
            "tensor([[0.4332, 0.4814, 0.0307, 0.0937],\n",
            "        [0.2324, 0.9749, 0.2147, 0.7320]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.7571, 0.7099, 0.8772, 0.5538], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-1.],\n",
            "        [ 1.],\n",
            "        [ 1.],\n",
            "        [-1.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.5000], requires_grad=True)\n",
            "Loss:\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "Truth table:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Z1VrHM-JFG"
      },
      "source": [
        "**Conclusions**\n",
        "\n",
        "As can be seen in each of the k (hidden neurons) the loss function returned 0, thus the calculations of the weights and bias were correct in each of the examples."
      ]
    }
  ]
}